{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje por transferencia\n",
    "\n",
    "En este notebook usará  modelos previamente entrenados para la detección de rostros y la predicción de edad y genero, es decir usará aprendizaje por transferencia o *transfer learning*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones Generales\n",
    "\n",
    "Este notebook usará inicialmente la librería [MTCNN](https://github.com/ipazc/mtcnn) para detectar rostros en una imagen, y posteriormente reutilizará el modelo VGGFace para predecir la edad y el genero de los rostros. En el siguente paper puede conocer más detalles del modelo VGGFace: *Qawaqneh, Z., Mallouh, A. A., & Barkana, B. D. (2017). Deep convolutional neural network for age estimation based on VGG-face model. arXiv preprint arXiv:1709.01664.*. https://arxiv.org/abs/1709.01664\n",
    "  \n",
    "Para realizar la actividad, solo siga las indicaciones asociadas a cada celda del notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar imagenes y librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación librerías\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "from numpy import asarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/face_1.jpeg\"\n",
    "pixels = pyplot.imread(filename, format='jpeg')\n",
    "pyplot.imshow(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/face_2.jpeg\"\n",
    "pixels = pyplot.imread(filename, format='jpeg')\n",
    "pyplot.imshow(pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraer rostro de una imagen\n",
    "\n",
    "Para ejecutar esta sección del código debe instalar la librería MTCNN con el comando *!pip install mtcnn*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación detector de rostros\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "# Definición detector de rostros\n",
    "detector = MTCNN()\n",
    "results = detector.detect_faces(pixels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para extraer rostros\n",
    "def get_face(img):\n",
    "    # Carga de imagen\n",
    "    pixels = pyplot.imread(img, format='jpeg')\n",
    "    results = detector.detect_faces(pixels)\n",
    "    # Extracción del rosto\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    face = pixels[y1:y2, x1:x2]\n",
    "    # Reescalar imagen a tamaño específico\n",
    "    required_size=(224, 224)\n",
    "    image = Image.fromarray(face)\n",
    "    image = image.resize(required_size)\n",
    "    face_array = asarray(image)\n",
    "    # Retornar rostro\n",
    "    return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = get_face(\"https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/face_1.jpeg\")\n",
    "pyplot.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = get_face(\"https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/face_2.jpeg\")\n",
    "pyplot.imshow(img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar embbeding (vector) para cada rostro\n",
    "\n",
    "Para ejecutar esta sección del código deben instalar la siguiente librería *!pip install keras_vggface*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_vggface.vggface import VGGFace\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si al instalar la librería sigue presentando algun error al cargarla, por favor correr el siguiente código en una celda adicional.\n",
    "<code>\n",
    "import sys\n",
    "path = '\\\\'.join(sys.executable.split('\\\\')[:-1])\n",
    "filename = path + \"\\\\lib\\\\site-packages\\\\keras_vggface\\\\models.py\"\n",
    "text = open(filename).read()\n",
    "open(filename, \"w+\").write(text.replace('keras.engine.topology', 'tensorflow.keras.utils'))\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición modelo vggface\n",
    "model = VGGFace(model='resnet50')\n",
    "\n",
    "# impresión de tamaño de inputs y outputs\n",
    "print('Inputs: %s' % model.inputs)\n",
    "print('Outputs: %s' % model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción embedding del modelo para rostro 1\n",
    "yhat1 = model.predict(img1[np.newaxis,:,:,:])\n",
    "print(yhat1.shape)\n",
    "yhat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción embedding del modelo para rostro 2\n",
    "yhat2 = model.predict(img2[np.newaxis,:,:,:])\n",
    "print(yhat2.shape)\n",
    "yhat2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predecir genero y edad\n",
    "\n",
    "Para ejecutar esta sección del código debe instalar la librería omegaconf con el comando *!pip install omegaconf*. Adicionalmente, debe descargar un archivo tipo '.hdf5' donde se encuentran los pesos calibrados del modelo preentrenado, esto se realiza con el código de la siguiente celda. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Definir dirección URL donde se encuentra el archivo \n",
    "remote_url = 'https://github.com/yu4u/age-gender-estimation/releases/download/v0.6/EfficientNetB3_224_weights.11-3.44.hdf5'\n",
    "# Definir nombre del archivo\n",
    "local_file = 'datasets/EfficientNetB3_224_weights.11-3.44.hdf5'\n",
    "# Hacer requerimiento con la función request.get() y guardar archivo\n",
    "data = requests.get(remote_url)\n",
    "with open(local_file, 'wb')as file:\n",
    "    file.write(data.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación librerías\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "\n",
    "WEIGHTS_FILE = 'datasets/EfficientNetB3_224_weights.11-3.44.hdf5'\n",
    "model_name, img_size = Path(WEIGHTS_FILE).stem.split(\"_\")[:2]\n",
    "cfg = OmegaConf.from_dotlist([f\"model.model_name={model_name}\", f\"model.img_size={img_size}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición modelo\n",
    "def get_model(cfg):\n",
    "    base_model = getattr(applications, cfg.model.model_name)(\n",
    "        include_top=False,\n",
    "        input_shape=(cfg.model.img_size, cfg.model.img_size, 3),\n",
    "        pooling=\"avg\"\n",
    "    )\n",
    "    features = base_model.output\n",
    "    # Capa adicional para predicción de genero\n",
    "    pred_gender = Dense(units=2, activation=\"softmax\", name=\"pred_gender\")(features)\n",
    "    # Capa adicional para predicción de edad\n",
    "    pred_age = Dense(units=101, activation=\"softmax\", name=\"pred_age\")(features)\n",
    "    model = Model(inputs=base_model.input, outputs=[pred_gender, pred_age])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo con set de parámetros\n",
    "model = get_model(cfg)\n",
    "model.load_weights(WEIGHTS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciónes del modelo imagen 1\n",
    "results = model.predict(img1[np.newaxis,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones imagen 1\n",
    "ages = np.arange(0, 101).reshape(101, 1)\n",
    "predicted_ages = results[1].dot(ages).flatten()\n",
    "predicted_genere = 'hombre' if (results[0][0][1] >= 0.5) else 'mujer'\n",
    "\n",
    "print('Edad imagen 1: ', predicted_ages)\n",
    "print('Genero imagen 1: ', predicted_genere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciónes del modelo imagen 2\n",
    "results = model.predict(img2[np.newaxis,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones imagen 2\n",
    "ages = np.arange(0, 101).reshape(101, 1)\n",
    "predicted_ages = results[1].dot(ages).flatten()\n",
    "predicted_genere = 'hombre' if (results[0][0][1] >= 0.5) else 'mujer'\n",
    "\n",
    "print('Edad imagen 2: ', predicted_ages)\n",
    "print('Genero imagen 2: ', predicted_genere)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
